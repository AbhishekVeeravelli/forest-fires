{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fire_forest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh9-NTPOt-cb"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCLX9f5iuWXi"
      },
      "source": [
        "classifier = Sequential()"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGPb7kZxucTz"
      },
      "source": [
        "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBLIwS7IuuEG"
      },
      "source": [
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY7moE1xvPjC"
      },
      "source": [
        "classifier.add(Flatten())"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEYetj7TvSOO"
      },
      "source": [
        "classifier.add(Dense(units = 128, activation = 'relu'))"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ff8cfKvVb7"
      },
      "source": [
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHpDBG4xvZpd"
      },
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb3ebWIewFvZ"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LncJmG4IxiNv",
        "outputId": "61e6b3d7-4098-4ce7-f410-8fbc2ba5cf72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git clone --recursive https://github.com/kalariya-parikshith/firedataset.git"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'firedataset' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnIDuwy1xp-Y",
        "outputId": "85907ca5-ad75-41d2-8aeb-5717134916ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls firedataset/Data/firedata"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train  valid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_si9yhcvcxW",
        "outputId": "2d99dbeb-aeec-4691-bc11-8d6d1efba815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "shear_range = 0.2,\n",
        "zoom_range = 0.2,\n",
        "horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/train1',target_size = (64, 64),batch_size = 32,class_mode = 'binary')\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/testf',target_size = (64, 64),batch_size = 32,class_mode = 'binary')"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 385 images belonging to 2 classes.\n",
            "Found 142 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-iZdyauIizV",
        "outputId": "d17ec8a7-fa88-4324-dcb3-2c2fa0eb9839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gem1os7Ps7J",
        "outputId": "c480cb2d-b98c-42c1-a94b-4d8f88e5f319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_set"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x7f6cb1207400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCQvk47KvtlQ",
        "outputId": "5e0a77dc-dfad-4bac-fb6f-57aa44d4c266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch = 10,\n",
        "                         epochs = 2,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = 200)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.8443WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n",
            "10/10 [==============================] - 3s 298ms/step - loss: 0.4079 - accuracy: 0.8443 - val_loss: 0.4663 - val_accuracy: 0.8028\n",
            "Epoch 2/2\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.3970 - accuracy: 0.8512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6cb0e90160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShlxJ8kv3cC3",
        "outputId": "c9bdb51c-7944-4298-8bc3-50338039ad2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "!ls firedataset/Data/firedata/test/notfire"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'images - 564.jpeg'  'images - 620.jpeg'  'images - 684.jpeg'\n",
            "'images - 565.jpeg'  'images - 622.jpeg'  'images - 689.jpeg'\n",
            "'images - 567.jpeg'  'images - 623.jpeg'  'images - 692.jpeg'\n",
            "'images - 568.jpeg'  'images - 625.jpeg'  'images - 693.jpeg'\n",
            "'images - 569.jpeg'  'images - 627.jpeg'  'images - 694.jpeg'\n",
            "'images - 570.jpeg'  'images - 629.jpeg'  'images - 695.jpeg'\n",
            "'images - 571.jpeg'  'images - 630.jpeg'  'images - 698.jpeg'\n",
            "'images - 572.jpeg'  'images - 631.jpeg'  'images - 700.jpeg'\n",
            "'images - 573.jpeg'  'images - 633.jpeg'  'images - 701.jpeg'\n",
            "'images - 578.jpeg'  'images - 634.jpeg'  'images - 702.jpeg'\n",
            "'images - 579.jpeg'  'images - 635.jpeg'  'images - 703.jpeg'\n",
            "'images - 580.jpeg'  'images - 637.jpeg'  'images - 706.jpeg'\n",
            "'images - 583.jpeg'  'images - 638.jpeg'  'images - 712.jpeg'\n",
            "'images - 585.jpeg'  'images - 639.jpeg'  'images - 713.jpeg'\n",
            "'images - 586.jpeg'  'images - 640.jpeg'  'images - 714.jpeg'\n",
            "'images - 588.jpeg'  'images - 642.jpeg'  'images - 716.jpeg'\n",
            "'images - 589.jpeg'  'images - 644.jpeg'  'images - 717.jpeg'\n",
            "'images - 590.jpeg'  'images - 645.jpeg'  'images - 718.jpeg'\n",
            "'images - 591.jpeg'  'images - 647.jpeg'  'images - 720.jpeg'\n",
            "'images - 592.jpeg'  'images - 648.jpeg'  'images - 721.jpeg'\n",
            "'images - 593.jpeg'  'images - 649.jpeg'  'images - 722.jpeg'\n",
            "'images - 595.jpeg'  'images - 650.jpeg'  'images - 725.jpeg'\n",
            "'images - 600.jpeg'  'images - 651.jpeg'  'images - 727.jpeg'\n",
            "'images - 601.jpeg'  'images - 655.jpeg'  'images - 729.jpeg'\n",
            "'images - 603.jpeg'  'images - 659.jpeg'  'images - 734.jpeg'\n",
            "'images - 604.jpeg'  'images - 662.jpeg'  'images - 735.jpeg'\n",
            "'images - 607.jpeg'  'images - 664.jpeg'  'images - 740.jpeg'\n",
            "'images - 608.jpeg'  'images - 666.jpeg'  'images - 742.jpeg'\n",
            "'images - 609.jpeg'  'images - 667.jpeg'  'images - 746.jpeg'\n",
            "'images - 611.jpeg'  'images - 668.jpeg'  'images - 749.jpeg'\n",
            "'images - 613.jpeg'  'images - 670.jpeg'  'Z - 6.jpeg'\n",
            "'images - 614.jpeg'  'images - 673.jpeg'  'Z - 7.jpeg'\n",
            "'images - 616.jpeg'  'images - 676.jpeg'  'Z - 8.jpeg'\n",
            "'images - 617.jpeg'  'images - 678.jpeg'  'Z - 9.jpeg'\n",
            "'images - 618.jpeg'  'images - 681.jpeg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Gc7BTMyMgu",
        "outputId": "3d4b6afa-0322-41cb-b910-ffafe6dc8297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/firedataset/Data/firedata/test/fire/images (100).jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "if result[0][0]==1:\n",
        "  prediction = 'notfire'\n",
        "else:\n",
        "  prediction = 'fire'\n",
        "print(prediction)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fire\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua32yflcCAo-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}